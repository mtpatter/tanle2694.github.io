---
layout: single
mathjax: true
title: Word embeddings
excerpt: "Mã hóa ngữ nghĩa"
modified: 2020-03-07
---


# **WORD EMBEDDINGS**: Mã hóa ngữ nghĩa 

## **1. Ý tưởng**
Trong NLP, hầu hết trong các trường hợp thì feature đều là các từ. Từ là ngôn ngữ của con người. Vậy làm sao có thể mô tả cho máy tính hiểu được?

**Cách 1:** Một cách đơn giản nhất là sử dụng mã ASCII của ký tự để mô tả từ. 

**Cách 2:** Một cách để mã hóa các từ thường gặp sẽ là one-hot-vector. Với $V$ là từ điển sử dụng, mỗi từ trong từ điển sẽ được mã hóa bởi vector thưa có $\|V\|$ chiều . Trong mỗi vector này có 1 số 1 ở vị trí là thứ tự của từ trong từ điển, còn lại là 0.

$$\overbrace{\left[0, 0, \dots, 1, \dots, 0, 0 \right]}^\text{|V| elements}$$


2 cách này dễ làm nhưng nhược điểm:

- Kích thước vector lớn $\Rightarrow$ Tốn bộ nhớ 
- Chỉ cho máy tính biết được đấy **là từ nào** , còn không cho biết nhiều về thông tin nó **nghĩa là gì**. Thuật ngữ **nghĩa là gì** ở đây được hiểu như thế nào. 

Tìm hiểu sự tương đồng qua một ví dụ sau đây:

Giả sử chúng ta có thể xây dựng được một language model(Tạm hiểu là có thể sinh ra một câu của một ngôn ngữ). Dữ liệu training có các câu:
- Nhà toán học đang xem xxx
- Nhà kinh tế đang xem xxx
- Nhà toán học đang tính lô

Sau quá trình training nó sẽ sinh ra  một câu mà chưa được nhìn thấy như sau:
- Nhà toán học đang xem xxx 

Câu sinh ra có vẻ đúng nhỉ vì:
- Nhà toán học và nhà kinh tế trong 2 câu training đầu có vẻ tương đồng nhau về mặt quy luật câu. Vì vậy chúng có gì đó tương đồng nhau (là danh từ) 
- Câu 1 và câu 3 dường như cũng có chung một quy luật với và có từ nhà toán học.

$\Rightarrow$ Câu sinh ra hoàn toàn hợp lệ. 2 từ nhà toán học và nhà kinh tế được gọi là có cùng *semantic similarity*




Liên tưởng đến các bài toán về xử lý ảnh. Ví dụ như mạng VGG-16 dùng để phân loại ảnh có kiến trúc như bên dưới:

![alt text](https://www.researchgate.net/profile/Max_Ferguson/publication/322512435/figure/fig3/AS:697390994567179@1543282378794/Fig-A1-The-standard-VGG-16-network-architecture-as-proposed-in-32-Note-that-only.png)

Với đầu vào là một ảnh có kích thước $[224, 224, 3]$ có tổng cộng là $224 * 224 * 3 = 150,528$ pixel. Sau khi một loạt các phép tính toán đến fc7 thì output sẽ là một vector 4,096 chiều và fc8 chỉ có nhiệm vụ phân loại xem ảnh đầu vào thuộc đối tượng nào.

Một bức ảnh chỉ biết độ sáng của các pixel đi qua một mạng neural network đưa ra được một vector ít chiều hơn hẳn và mang các đặc trưng của ảnh(ngữ nghĩa của ảnh) có thể phân loại các ảnh có sự tương đồng.

**Cách 3:** Vậy thì nếu ta xây dựng một mạng neural với input là một one-hot-vectors và output là một vector mang ngữ nghĩa, có số chiều ít hơn hẳn thì cũng có thể đấy nhỉ :D.


## **2. Tạo ra một dense word embeddings**
Dense word embedding là một vectors chứa các số thực, mã hóa từng từ trong từ điển mà ta đang sử dụng.

Với 2 mục đích: Vector có kích thước nhỏ và có cùng ngữ nghĩa. 

Vậy định nghĩa của 2 đích đến này như thế nào?


Solution sẽ là:
- Vector có kích thước nhỏ đơn giản là ta xem số chiều của nó có lớn hay không.
- Đo độ tương đồng ngữ nghĩa sẽ là dùng một độ đo score nào đấy. Mỗi thành phần của vector sẽ là một thuộc tính của từ.

![.](https://drive.google.com/uc?export=download&id=1nezJlfX1bwsUg1otLEqMdVf-TASQDffx)

Như ảnh ở trên thì thì các từ được biểu diễn bởi các vector 3 chiều. Khi đó ta có thể  sử dụng các độ đo như Cosin hay Euclidean để đo độ tương đồng.

Việc định nghĩa các attributes như thế nào cho phù hợp(các từ tương đồng có sự tương quan lớn, các từ không tương đồng sẽ có sự tương quan nhỏ). 

Vậy nên khó quá thì để máy nó tự học vậy theo solution 3 như ở trên đưa ra.




